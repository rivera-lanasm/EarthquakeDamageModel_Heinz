{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import fiona\n",
    "import pyogrio\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOWNLOAD BUILDING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to download building data, extract it, then aggregate the data to count the number of building for each census tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the webpage to scrape\n",
    "url = \"https://disasters.geoplatform.gov/USA_Structures/\"\n",
    "\n",
    "def fetch_state_links():\n",
    "    \"\"\"Fetches state names and their corresponding links from the webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        return {link.text.strip(): link[\"href\"] for link in links if \"Deliverable\" in link[\"href\"]}\n",
    "    else:\n",
    "        print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n",
    "        return {}\n",
    "\n",
    "def get_link_by_state(state_name, state_links):\n",
    "    \"\"\"Returns the link for a given state name.\"\"\"\n",
    "    return state_links.get(state_name, \"State not found\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_zip(state_name, state_links):\n",
    "    \"\"\"Downloads and extracts a ZIP file from the given URL.\"\"\"\n",
    "    url = get_link_by_state(state_name, state_links)\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "    output_dir = os.path.join(parent_dir, 'Data', 'building_data_gdb')\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        zip_path = os.path.join(output_dir, f\"{state_name}_Structures.zip\")\n",
    "        \n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_dir)\n",
    "        \n",
    "        os.remove(zip_path)\n",
    "        print(f\"Downloaded, extracted, and deleted ZIP file for {state_name} to {output_dir}\")\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_links = fetch_state_links()\n",
    "# download_and_extract_zip(\"Alaska\", state_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded, extracted, and deleted ZIP file for Alabama to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Alaska to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for American Samoa to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Arizona to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Arkansas to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for California to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Colorado to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Connecticut to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Delaware to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for D.C. to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Guam to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Florida to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Georgia to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Hawaii to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Idaho to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Illinois to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Indiana to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Iowa to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Kansas to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Kentucky to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Louisiana to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Maine to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Maryland to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Massachusetts to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Michigan to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Minnesota to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Missouri to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Mississippi to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Montana to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Nebraska to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Nevada to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for New Hampshire to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for New Jersey to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for New Mexico to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for New York to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for North Carolina to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for North Dakota to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Northern Mariana Islands to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Ohio to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Oklahoma to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Oregon to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Pennsylvania to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Puerto Rico to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Rhode Island to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for South Carolina to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for South Dakota to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Tennessee to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Texas to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Utah to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Vermont to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Virgin Islands to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Virginia to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Washington to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for West Virginia to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Wisconsin to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n",
      "Downloaded, extracted, and deleted ZIP file for Wyoming to c:\\Users\\ysurya\\Documents\\EarthquakeDamageModel_Heinz\\Data\\building_data_gdb\n"
     ]
    }
   ],
   "source": [
    "for state in state_links:\n",
    "    download_and_extract_zip(state, state_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ BUILDING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_building_data_directory(stateid):\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # get parent directory\n",
    "    parent_dir = os.path.dirname(cwd)\n",
    "    # get the building data directory\n",
    "    building_data_directory = os.path.join(parent_dir, 'Data', 'building_data_gdb')\n",
    "    # find all folder in the building data directory\n",
    "    folders = [f for f in os.listdir(building_data_directory) if os.path.isdir(os.path.join(building_data_directory, f))]\n",
    "    # get the folder that ends with stateid\n",
    "    stateid_dir= [f for f in folders if f.endswith(f'{stateid}')][0]\n",
    "\n",
    "    return os.path.join(building_data_directory, stateid_dir, f'{stateid}_Structures.gdb')\n",
    "\n",
    "def get_building_data_csv(stateid):\n",
    "    building_data_directory = get_building_data_directory(stateid)\n",
    "\n",
    "    # get the csv file\n",
    "    return os.path.join(building_data_directory, f'{stateid}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if false makedir\n",
    "def create_directory_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    else:\n",
    "        print(f\"Directory {directory} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read only the specified columns\n",
    "def read_cols(path):\n",
    "    cols = ['OCC_CLS', 'PRIM_OCC', 'CENSUSCODE', 'LONGITUDE', 'LATITUDE']\n",
    "    return gpd.read_file(path, columns=cols)\n",
    "    \n",
    "# only read specific columns, it can reduce the memory usage and time for each state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a csv file for a state is exists\n",
    "    # if exists, read it\n",
    "    # if not, check if the gdb file exists\n",
    "    # if exists, read it\n",
    "def read_building_data(stateid):\n",
    "    building_data_directory = get_building_data_directory(stateid)\n",
    "\n",
    "    # get the csv file\n",
    "    csv_path = get_building_data_csv(stateid)\n",
    "\n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"Reading {csv_path}\")\n",
    "        return gpd.read_file(csv_path)\n",
    "    else:\n",
    "        print(f\"{csv_path} does not exist.\")\n",
    "        gdb_path = os.path.join(building_data_directory)\n",
    "        if os.path.exists(gdb_path):\n",
    "            print(f\"Reading {gdb_path}\")\n",
    "            return read_cols(gdb_path)\n",
    "        else:\n",
    "            print(f\"{gdb_path} does not exist.\")\n",
    "            print(\"Please download the gdb file from the USGS website.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_data = [\n",
    "    #(\"Alabama\", \"AL\"), (\"Alaska\", \"AK\"), (\"Arizona\", \"AZ\"), (\"Arkansas\", \"AR\"),\n",
    "    (\"California\", \"CA\"), (\"Colorado\", \"CO\"), (\"Connecticut\", \"CT\"), (\"Delaware\", \"DE\"),\n",
    "    (\"Florida\", \"FL\"), (\"Georgia\", \"GA\"), (\"Hawaii\", \"HI\"), (\"Idaho\", \"ID\"),\n",
    "    (\"Illinois\", \"IL\"), (\"Indiana\", \"IN\"), (\"Iowa\", \"IA\"), (\"Kansas\", \"KS\"),\n",
    "    (\"Kentucky\", \"KY\"), (\"Louisiana\", \"LA\"), (\"Maine\", \"ME\"), (\"Maryland\", \"MD\"),\n",
    "    (\"Massachusetts\", \"MA\"), (\"Michigan\", \"MI\"), (\"Minnesota\", \"MN\"), (\"Mississippi\", \"MS\"),\n",
    "    (\"Missouri\", \"MO\"), (\"Montana\", \"MT\"), (\"Nebraska\", \"NE\"), (\"Nevada\", \"NV\"),\n",
    "    (\"New Hampshire\", \"NH\"), (\"New Jersey\", \"NJ\"), (\"New Mexico\", \"NM\"), (\"New York\", \"NY\"),\n",
    "    (\"North Carolina\", \"NC\"), (\"North Dakota\", \"ND\"), (\"Ohio\", \"OH\"), (\"Oklahoma\", \"OK\"),\n",
    "    (\"Oregon\", \"OR\"), (\"Pennsylvania\", \"PA\"), (\"Rhode Island\", \"RI\"), (\"South Carolina\", \"SC\"),\n",
    "    (\"South Dakota\", \"SD\"), (\"Tennessee\", \"TN\"), (\"Texas\", \"TX\"), (\"Utah\", \"UT\"),\n",
    "    (\"Vermont\", \"VT\"), (\"Virginia\", \"VA\"), (\"Washington\", \"WA\"), (\"West Virginia\", \"WV\"),\n",
    "    (\"Wisconsin\", \"WI\"), (\"Wyoming\", \"WY\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGGREGATE BUILDING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remap OCC_CLS and PRIM_OCC\n",
    "def remap_occupancy_classes(gdf):\n",
    "    # Define the mapping dictionaries\n",
    "    building_data = gdf[['BUILD_ID', 'OCC_CLS', 'PRIM_OCC', 'SQFEET', 'FIPS', 'CENSUSCODE', 'LONGITUDE', 'LATITUDE', \n",
    "                    'geometry']]\n",
    "    # mapping the occupancy class\n",
    "    mapping = {\n",
    "        'Agriculture':'OTHER', 'Education':'OTHER', 'Residential':'RESIDENTIAL', 'Unclassified':'OTHER',\n",
    "        'Commercial':'OTHER', 'Government':'OTHER', 'Industrial':'OTHER', 'Utility and Misc':'OTHER',\n",
    "        'Assembly':'OTHER'\n",
    "    }\n",
    "    building_data['OCC_CLS'] = building_data['OCC_CLS'].map(mapping)\n",
    "\n",
    "    # mapping the primary occupancy\n",
    "    mapping = {i:'OTHER' for i in building_data['PRIM_OCC'].unique() if i not in ['Single Family Dwelling', 'Multi - Family Dwelling']}\n",
    "    residential = {'Single Family Dwelling':'SINGLE FAMILY', 'Multi - Family Dwelling':'MULTI FAMILY'}\n",
    "    mapping.update(residential)\n",
    "    building_data['PRIM_OCC'] = building_data['PRIM_OCC'].map(mapping)\n",
    "    return building_data\n",
    "\n",
    "\n",
    "# function to aggregate the building counts by GEODI, OCC_CLS, PRIM_OCC\n",
    "def aggregate_building_counts(gdf):\n",
    "    building_data = remap_occupancy_classes(gdf)\n",
    "    # group by GEODI, OCC_CLS, PRIM_OCC and sum the counts\n",
    "    count_building_data = building_data.groupby(['CENSUSCODE', 'OCC_CLS', 'PRIM_OCC']).agg({'BUILD_ID':'count', 'SQFEET':'sum'}).reset_index()\n",
    "    # rename the columns\n",
    "    count_building_data = count_building_data.rename(columns={'BUILD_ID':'COUNT'})\n",
    "    return count_building_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_building_data(count_building_data):\n",
    "    df = count_building_data.copy()\n",
    "\n",
    "    # Create a pivot table\n",
    "    df_pivot = df.pivot_table(index=\"CENSUSCODE\", columns=[\"OCC_CLS\", \"PRIM_OCC\"], values=\"COUNT\", aggfunc=\"sum\", fill_value=0)\n",
    "\n",
    "    # Flatten MultiIndex columns\n",
    "    df_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in df_pivot.columns]\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states_data:\n",
    "    state_name, stateid = state\n",
    "    print(f\"Reading building data for {state_name}\")\n",
    "    gdf = read_building_data(stateid)\n",
    "    if gdf is not None:\n",
    "        count_building_data = aggregate_building_counts(gdf)\n",
    "        df_pivot = pivot_building_data(count_building_data)\n",
    "        output_dir = os.path.join(os.path.dirname(os.getcwd()), 'Data', 'building_data_csv')\n",
    "        create_directory_if_not_exists(output_dir)\n",
    "        output_path = os.path.join(output_dir, f\"{stateid}_building_data.csv\")\n",
    "        df_pivot.to_csv(output_path, index=False)\n",
    "        print(f\"Saved building data for {state_name} to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
